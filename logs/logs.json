{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'text'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py\", line 143, in _run_pipeline\n    result = await workflow_function(config, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/create_base_text_units.py\", line 32, in run_workflow\n    output = create_base_text_units(\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/create_base_text_units.py\", line 64, in create_base_text_units\n    zip(*[sort[col] for col in [\"id\", \"text\"]], strict=True)\n          ~~~~^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/pandas/core/frame.py\", line 4102, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'text'\n",
    "source": "'text'",
    "details": null
}
{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'text'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py\", line 143, in _run_pipeline\n    result = await workflow_function(config, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/create_base_text_units.py\", line 32, in run_workflow\n    output = create_base_text_units(\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/create_base_text_units.py\", line 64, in create_base_text_units\n    zip(*[sort[col] for col in [\"id\", \"text\"]], strict=True)\n          ~~~~^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/pandas/core/frame.py\", line 4102, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'text'\n",
    "source": "'text'",
    "details": null
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": {
        "prompt": [
            "# C++ Programming Community\n\nThe community revolves around the C++ programming language, which is a superset of C and adds object-oriented programming features. The community includes the FILE data type and the TMPFILE function, which are integral components of C++ programming.\n\n## C++ as the central language\n\nC++ is the central entity in this community, serving as the primary programming language. Its significance is underscored by its widespread use in software development and its role in the broader field of computer science. The language's object-oriented features add complexity and depth to its applications, making it a crucial component of the community. [Data: Entities (6), Relationships (7)]\n\n## FILE data type's role\n\nThe FILE data type is a fundamental component of C++ programming, used to represent a sequence of bytes. Its importance is highlighted by its widespread use in file handling operations. The relationship between C++ and FILE is crucial in understanding the technical aspects of the community. [Data: Entities (1), Relationships (7)]\n\n## TMPFILE function's significance\n\nThe TMPFILE function is a crucial component of C++ programming, used to create temporary files. Its significance is underscored by its widespread use in various applications, including testing and development. The relationship between TMPFILE and FILE is essential in understanding the technical aspects of the community. [Data: Entities (0), Relationships (0, 1)]\n\n## Relationship between C++ and FILE\n\nC++ uses the FILE data type, which is a fundamental component of the language. This relationship underscores the technical nature of the community and highlights the importance of the FILE data type in C++ programming. [Data: Entities (6, 1), Relationships (7)]\n\n## Relationship between TMPFILE and FILE\n\nTMPFILE uses the FILE data type, which is a fundamental component of C++ programming. This relationship underscores the technical nature of the community and highlights the importance of the FILE data type in C++ programming. [Data: Entities (0, 1), Relationships (0, 1)]",
            "# C Programming Language and Related Functions\n\nThe community revolves around the C programming language, which is a general-purpose programming language. The community includes entities such as FREAD, SIZE_T, FILE, FWRITE, and FWRITE_UNLOCKED, all of which are related to file operations and data types in C.\n\n## C Programming Language as the central entity\n\nC is the central entity in this community, serving as the general-purpose programming language. This language is the common link between all other entities, suggesting its significance in the community. The community's focus on C and its related functions indicates a technical and educational context. [Data: Entities (5), Relationships (4, 6)]\n\n## SIZE_T as a fundamental data type\n\nSIZE_T is a fundamental data type in the C programming language, used to represent the size of objects in bytes. It is a crucial component of memory management and data structures in C. The community's focus on SIZE_T indicates its importance in the technical context. [Data: Entities (4), Relationships (1, 4)]\n\n## FREAD function for reading data\n\nFREAD is a function used in C and C++ programming languages for reading data from a file. The function uses the type SIZE_T to specify the number of bytes to read. The community's focus on FREAD indicates its importance in file operations. [Data: Entities (3), Relationships (1)]\n\n## FWRITE function for writing data\n\nFWRITE is a function in C that writes data to a file. The function uses the type SIZE_T to specify the number of bytes to write. The community's focus on FWRITE indicates its importance in file operations. [Data: Entities (7), Relationships (8)]\n\n## FWRITE_UNLOCKED function for writing data\n\nFWRITE_UNLOCKED is a function that uses the type SIZE_T for its operations. The community's focus on FWRITE_UNLOCKED indicates its importance in file operations, particularly in scenarios where thread safety is not a concern. [Data: Entities (9), Relationships (9)]",
            "# POPOP and its Relationship with FILE and SUBPROCESS\n\nThe community revolves around the 'popen' function, which is used to open a file in a subprocess. The 'popen' function has relationships with the 'FILE' type and the 'SUBPROCESS' type, all of which are essential components in the execution of the function.\n\n## POPOP as the central function\n\nPOPOP is the central entity in this community, serving as the function used to open a file in a subprocess. This function is a key component in the execution of subprocesses and could be used for various purposes, such as reading or writing to files. The relationship between POPOP and the FILE type is crucial in understanding the functionality of this community. [Data: Entities (10), Relationships (10)]\n\n## FILE as the target of POPOP\n\nFILE is the target of the POPOP function, representing the file that is opened in a subprocess. This file could be used for various purposes, such as reading or writing data. The relationship between POPOP and the FILE type is crucial in understanding the functionality of this community. [Data: Entities (11), Relationships (10)]\n\n## SUBPROCESS as the context of POPOP\n\nSUBPROCESS is the context in which the POPOP function is executed, representing the separate process that is created and run by another process. This subprocess could be used for various purposes, such as running a command or executing a program. The relationship between POPOP and the SUBPROCESS type is crucial in understanding the functionality of this community. [Data: Entities (11), Relationships (11)]\n\n## Role of POPOP in the execution of subprocesses\n\nPOPOP is a key function in the execution of subprocesses, allowing for the opening of files in a separate process. This function could be used for various purposes, such as reading or writing data. The relationship between POPOP and the FILE and SUBPROCESS types is crucial in understanding the functionality of this community. [Data: Relationships (10, 11)]\n\n## Technical nature of the entities involved\n\nThe entities involved in this community are technical in nature, representing the 'popen' function, the 'FILE' type, and the 'SUBPROCESS' type. These entities are essential components in the execution of subprocesses and could be used for various purposes, such as reading or writing data. The technical nature of these entities suggests that the community is focused on technical aspects and could be of interest to individuals or organizations with a technical background. [Data: Entities (10, 11), Relationships (10, 11)]"
        ],
        "kwargs": {}
    }
}
{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py\", line 143, in _run_pipeline\n    result = await workflow_function(config, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 63, in run_workflow\n    output = await generate_text_embeddings(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 154, in generate_text_embeddings\n    outputs[field] = await _run_and_snapshot_embeddings(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 173, in _run_and_snapshot_embeddings\n    data[\"embedding\"] = await embed_text(\n                        ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 59, in embed_text\n    return await _text_embed_with_vector_store(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 153, in _text_embed_with_vector_store\n    result = await strategy_exec(texts, callbacks, cache, strategy_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 68, in run\n    embeddings = await _execute(model, text_batches, ticker, semaphore)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 97, in _execute\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 91, in embed\n    chunk_embeddings = await model.aembed_batch(chunk)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py\", line 185, in aembed_batch\n    response = await self.model(text_list, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": null
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/cache/json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/cache/json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/storage/file_pipeline_storage.py\", line 134, in delete\n    await remove(join_path(self._root_dir, key))\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/aiofiles/ospath.py\", line 14, in run\n    return await loop.run_in_executor(executor, pfunc)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/home/hyz0906/study/neo4j_graph/cache/extract_graph/chat_extract-continuation-0_63f484cee6a8ef206f6a6597d165757afaa78989ea7914efbd2e5080bccd8069_v2'\n",
    "source": "[Errno 2] No such file or directory: '/home/hyz0906/study/neo4j_graph/cache/extract_graph/chat_extract-continuation-0_63f484cee6a8ef206f6a6597d165757afaa78989ea7914efbd2e5080bccd8069_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/cache/json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py\", line 84, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/cache/json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/storage/file_pipeline_storage.py\", line 134, in delete\n    await remove(join_path(self._root_dir, key))\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/aiofiles/ospath.py\", line 14, in run\n    return await loop.run_in_executor(executor, pfunc)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/home/hyz0906/study/neo4j_graph/cache/extract_graph/chat_extract-continuation-0_63f484cee6a8ef206f6a6597d165757afaa78989ea7914efbd2e5080bccd8069_v2'\n",
    "source": "[Errno 2] No such file or directory: '/home/hyz0906/study/neo4j_graph/cache/extract_graph/chat_extract-continuation-0_63f484cee6a8ef206f6a6597d165757afaa78989ea7914efbd2e5080bccd8069_v2'",
    "details": {
        "doc_index": 0,
        "text": "function ftell"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": {
        "prompt": [
            "# C Programming Functions and Data Types\n\nThe community revolves around key entities in C programming, including functions like fread, fwrite, and fwrite_unlocked, and data types like size_t. These entities are interconnected through relationships that highlight their roles in file operations and memory management.\n\n## fread and fwrite as file operations\n\nfread and fwrite are fundamental functions in C used for reading and writing data to files, respectively. Their relationship with the data type size_t is crucial for specifying the number of bytes to read or write. These functions are essential for file handling and data management in C programs. [Data: Entities (3, 5); Relationships (1, 2)]\n\n## fwrite_unlocked and size_t\n\nfwrite_unlocked is a variant of fwrite that is not locked, and it also uses the data type size_t for its operations. This indicates that fwrite_unlocked is designed for performance-critical applications where locking is not necessary. The relationship between fwrite_unlocked and size_t is significant in understanding the performance implications of file operations in C. [Data: Entities (5, 7); Relationships (3)]\n\n## size_t as an unsigned integral type\n\nsize_t is an unsigned integral type used to represent the size of objects in bytes. It is a fundamental data type in C and C++ that ensures non-negative values, making it suitable for indexing and sizing operations in memory management and data structures. The significance of size_t lies in its role as a universal size representation across different platforms. [Data: Entities (4); Relationships (1, 2, 3)]\n\n## Interconnectedness of entities\n\nThe entities in this community are interconnected through relationships that highlight their roles in file operations and memory management. The relationship between fread, fwrite, and fwrite_unlocked with size_t demonstrates the importance of data types in defining the behavior of functions. This interconnectedness is essential for understanding the technical aspects of C programming. [Data: Entities (3, 5, 7); Relationships (1, 2, 3)]\n\n## Role of fread in file operations\n\nfread is a function used in C and C++ programming languages for reading data from a file. It uses the data type size_t to specify the number of bytes to read, making it a crucial function for file handling. The relationship between fread and size_t is significant in understanding the technical aspects of file operations in C. [Data: Entities (3, 4); Relationships (1)]"
        ],
        "kwargs": {}
    }
}
{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py\", line 143, in _run_pipeline\n    result = await workflow_function(config, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 63, in run_workflow\n    output = await generate_text_embeddings(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 154, in generate_text_embeddings\n    outputs[field] = await _run_and_snapshot_embeddings(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 173, in _run_and_snapshot_embeddings\n    data[\"embedding\"] = await embed_text(\n                        ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 59, in embed_text\n    return await _text_embed_with_vector_store(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 153, in _text_embed_with_vector_store\n    result = await strategy_exec(texts, callbacks, cache, strategy_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 68, in run\n    embeddings = await _execute(model, text_batches, ticker, semaphore)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 97, in _execute\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 91, in embed\n    chunk_embeddings = await model.aembed_batch(chunk)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py\", line 185, in aembed_batch\n    response = await self.model(text_list, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": null
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": {
        "prompt": [
            "# C Programming Functions and Data Types\n\nThe community revolves around key entities in C programming, including functions like fread, fwrite, and fwrite_unlocked, and data types like size_t. These entities are interconnected through relationships that highlight their roles in file operations and memory management.\n\n## fread and fwrite as file operations\n\nfread and fwrite are fundamental functions in C used for reading and writing data to files, respectively. Their relationship with the data type size_t is crucial for specifying the number of bytes to read or write. These functions are essential for file handling and data management in C programs. [Data: Entities (3, 5); Relationships (1, 2)]\n\n## fwrite_unlocked and size_t\n\nfwrite_unlocked is a variant of fwrite that is not locked, and it also uses the data type size_t for its operations. This indicates that fwrite_unlocked is designed for performance-critical applications where locking is not necessary. The relationship between fwrite_unlocked and size_t is significant in understanding the performance implications of file operations in C. [Data: Entities (5, 7); Relationships (3)]\n\n## size_t as an unsigned integral type\n\nsize_t is an unsigned integral type used to represent the size of objects in bytes. It is a fundamental data type in C and C++ that ensures non-negative values, making it suitable for indexing and sizing operations in memory management and data structures. The significance of size_t lies in its role as a universal size representation across different platforms. [Data: Entities (4); Relationships (1, 2, 3)]\n\n## Interconnectedness of entities\n\nThe entities in this community are interconnected through relationships that highlight their roles in file operations and memory management. The relationship between fread, fwrite, and fwrite_unlocked with size_t demonstrates the importance of data types in defining the behavior of functions. This interconnectedness is essential for understanding the technical aspects of C programming. [Data: Entities (3, 5, 7); Relationships (1, 2, 3)]\n\n## Role of fread in file operations\n\nfread is a function used in C and C++ programming languages for reading data from a file. It uses the data type size_t to specify the number of bytes to read, making it a crucial function for file handling. The relationship between fread and size_t is significant in understanding the technical aspects of file operations in C. [Data: Entities (3, 4); Relationships (1)]"
        ],
        "kwargs": {}
    }
}
{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py\", line 143, in _run_pipeline\n    result = await workflow_function(config, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 63, in run_workflow\n    output = await generate_text_embeddings(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 154, in generate_text_embeddings\n    outputs[field] = await _run_and_snapshot_embeddings(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 173, in _run_and_snapshot_embeddings\n    data[\"embedding\"] = await embed_text(\n                        ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 59, in embed_text\n    return await _text_embed_with_vector_store(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 153, in _text_embed_with_vector_store\n    result = await strategy_exec(texts, callbacks, cache, strategy_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 68, in run\n    embeddings = await _execute(model, text_batches, ticker, semaphore)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 97, in _execute\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 91, in embed\n    chunk_embeddings = await model.aembed_batch(chunk)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py\", line 185, in aembed_batch\n    response = await self.model(text_list, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": null
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": {
        "prompt": [
            "# C Programming Functions and Data Types\n\nThe community revolves around key entities in C programming, including functions like fread, fwrite, and fwrite_unlocked, and data types like size_t. These entities are interconnected through relationships that highlight their roles in file operations and memory management.\n\n## fread and fwrite as file operations\n\nfread and fwrite are fundamental functions in C used for reading and writing data to files, respectively. Their relationship with the data type size_t is crucial for specifying the number of bytes to read or write. These functions are essential for file handling and data management in C programs. [Data: Entities (3, 5); Relationships (1, 2)]\n\n## fwrite_unlocked and size_t\n\nfwrite_unlocked is a variant of fwrite that is not locked, and it also uses the data type size_t for its operations. This indicates that fwrite_unlocked is designed for performance-critical applications where locking is not necessary. The relationship between fwrite_unlocked and size_t is significant in understanding the performance implications of file operations in C. [Data: Entities (5, 7); Relationships (3)]\n\n## size_t as an unsigned integral type\n\nsize_t is an unsigned integral type used to represent the size of objects in bytes. It is a fundamental data type in C and C++ that ensures non-negative values, making it suitable for indexing and sizing operations in memory management and data structures. The significance of size_t lies in its role as a universal size representation across different platforms. [Data: Entities (4); Relationships (1, 2, 3)]\n\n## Interconnectedness of entities\n\nThe entities in this community are interconnected through relationships that highlight their roles in file operations and memory management. The relationship between fread, fwrite, and fwrite_unlocked with size_t demonstrates the importance of data types in defining the behavior of functions. This interconnectedness is essential for understanding the technical aspects of C programming. [Data: Entities (3, 5, 7); Relationships (1, 2, 3)]\n\n## Role of fread in file operations\n\nfread is a function used in C and C++ programming languages for reading data from a file. It uses the data type size_t to specify the number of bytes to read, making it a crucial function for file handling. The relationship between fread and size_t is significant in understanding the technical aspects of file operations in C. [Data: Entities (3, 4); Relationships (1)]"
        ],
        "kwargs": {}
    }
}
{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py\", line 143, in _run_pipeline\n    result = await workflow_function(config, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 63, in run_workflow\n    output = await generate_text_embeddings(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 154, in generate_text_embeddings\n    outputs[field] = await _run_and_snapshot_embeddings(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/workflows/generate_text_embeddings.py\", line 173, in _run_and_snapshot_embeddings\n    data[\"embedding\"] = await embed_text(\n                        ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 59, in embed_text\n    return await _text_embed_with_vector_store(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/embed_text.py\", line 153, in _text_embed_with_vector_store\n    result = await strategy_exec(texts, callbacks, cache, strategy_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 68, in run\n    embeddings = await _execute(model, text_batches, ticker, semaphore)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 97, in _execute\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/index/operations/embed_text/strategies/openai.py\", line 91, in embed\n    chunk_embeddings = await model.aembed_batch(chunk)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py\", line 185, in aembed_batch\n    response = await self.model(text_list, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/base/base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/fnllm/openai/llm/openai_embeddings_llm.py\", line 126, in _execute_llm\n    result = await self._client.embeddings.create(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 243, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyz0906/.local/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}\n",
    "source": "Error code: 413 - {'code': 20042, 'message': 'input must have less than 512 tokens', 'data': None}",
    "details": null
}
